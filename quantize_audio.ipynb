{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d7add39",
   "metadata": {},
   "source": [
    "Code assumes that data is in same directory as capstone_repo directory:  \n",
    "```\n",
    "capstone_repo  \n",
    "│   README.md  \n",
    "│   gsc_mfcc_extraction.ipynb    \n",
    "│  \n",
    "speech_commands_v0.02  \n",
    "└───backward  \n",
    "│   │   file01.wav  \n",
    "│   │   file02.wav (etc)  \n",
    "└───bed  \n",
    "│   |..etc  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2331b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import time\n",
    "import pandas as pd\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee295c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/Users/Shared/back up fix/speech_commands_v0.02/'\n",
    "data_path = '../speech_commands_v0.02/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f6d77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../speech_commands_v0.02',\n",
       " ['backward',\n",
       "  'bed',\n",
       "  'bird',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'down',\n",
       "  'eight',\n",
       "  'five',\n",
       "  'follow',\n",
       "  'forward',\n",
       "  'four',\n",
       "  'go',\n",
       "  'happy',\n",
       "  'house',\n",
       "  'learn',\n",
       "  'left',\n",
       "  'marvin',\n",
       "  'nine',\n",
       "  'no',\n",
       "  'off',\n",
       "  'on',\n",
       "  'one',\n",
       "  'right',\n",
       "  'seven',\n",
       "  'sheila',\n",
       "  'six',\n",
       "  'stop',\n",
       "  'three',\n",
       "  'tree',\n",
       "  'two',\n",
       "  'up',\n",
       "  'visual',\n",
       "  'wow',\n",
       "  'yes',\n",
       "  'zero',\n",
       "  '_background_noise_'],\n",
       " ['.DS_Store',\n",
       "  'LICENSE',\n",
       "  'README.md',\n",
       "  'testing_list.txt',\n",
       "  'validation_list.txt'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of word directories in speech commands dataset\n",
    "list(os.walk(data_path))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5286dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ['backward',\n",
    "  'bed',\n",
    "  'bird',\n",
    "  'cat',\n",
    "  'dog',\n",
    "  'down',\n",
    "  'eight',\n",
    "  'five',\n",
    "  'follow',\n",
    "  'forward',\n",
    "  'four',\n",
    "  'go',\n",
    "  'happy',\n",
    "  'house',\n",
    "  'learn',\n",
    "  'left',\n",
    "  'marvin',\n",
    "  'nine',\n",
    "  'no',\n",
    "  'off',\n",
    "  'on',\n",
    "  'one',\n",
    "  'right',\n",
    "  'seven',\n",
    "  'sheila',\n",
    "  'six',\n",
    "  'stop',\n",
    "  'three',\n",
    "  'tree',\n",
    "  'two',\n",
    "  'up',\n",
    "  'visual',\n",
    "  'wow',\n",
    "  'yes',\n",
    "  'zero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f88ba77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only these 20 words will act as keywords\n",
    "word_list = ['up','down','left', 'right', 'stop', 'go', 'yes', 'no', 'on', 'off', 'one', 'two', \n",
    "             'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero']\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64c3178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backward', 'bed', 'bird', 'cat', 'dog', 'follow', 'forward', 'happy', 'house', 'learn', 'marvin', 'sheila', 'tree', 'visual', 'wow']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the other 15 words will be combined into one class of rejection words\n",
    "rejection_words = [i for i in all_words if i not in word_list]\n",
    "print(rejection_words)\n",
    "len(rejection_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7e64b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to see if one audio file will work correctly\n",
    "y, sr = librosa.load((data_path + '/bird/0a7c2a8d_nohash_0.wav'), sr = 16000)\n",
    "y1, sr1 = librosa.load((data_path + '/down/00f0204f_nohash_0.wav'), sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "eeeef4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_data(data, num_bits = 8, data_min=-1, data_max=1):\n",
    "    '''\n",
    "    Quantizes audio data based on number of bits and desired minimum and maximum\n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    data - array containing time series of audio\n",
    "    num_bits - integer specifying number of bits to use, default 8 for MAX78000\n",
    "    data_min - desired minimum of quantized data\n",
    "    data_max - desired maximum of quantized data\n",
    "    \n",
    "    Returns:\n",
    "    ------------\n",
    "    q_data - array with quantized data between data_min and data_max\n",
    "    '''\n",
    "    \n",
    "    step_size = 2.0/(2**num_bits)\n",
    "    max_val = 2**num_bits -1\n",
    "    q_data = np.round(data / step_size)\n",
    "    q_data = np.clip(q_data, np.round(-max_val / 2), np.round(max_val/2))\n",
    "    q_data = q_data / (2**num_bits / 2)\n",
    "    q_data = np.clip(q_data, data_min, data_max)\n",
    "    return q_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "16dd2aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4867\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "#let's test if quantize audio works as intended:\n",
    "print(len(np.unique(y)))\n",
    "yq = quantize_data(y)\n",
    "print(len(np.unique(yq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73b4bd",
   "metadata": {},
   "source": [
    "Converts test file y from 4867 values to 75 unique values. Is this what we should expect? Since our quantize function works with a uniform spacing of step_size, our y test file should have a range of about 75 / 256 before quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6835b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.289 percent of possible values are represented in original audio file\n",
      "So we should expect approximately 73.984 unique values in the transformed file\n"
     ]
    }
   ],
   "source": [
    "percent = np.round(((y.max() - y.min()) / 2),3)\n",
    "print(percent, 'percent of possible values are represented in original audio file')\n",
    "print('So we should expect approximately', percent * 256, 'unique values in the transformed file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5308ffe",
   "metadata": {},
   "source": [
    "Let's try with another file y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7854853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.568 values expected\n",
      "45 unique values after\n"
     ]
    }
   ],
   "source": [
    "expected = np.round(((y1.max() - y1.min()) / 2),3) * 256\n",
    "yq1 = quantize_data(y1)\n",
    "print(expected, 'values expected')\n",
    "print(len(np.unique(yq1)), 'unique values after')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99298a9",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d6d5327",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1464/3282342200.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m#load audio file, GSC is sampled at 16000Hz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# quantize data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;31m# Otherwise, create the soundfile object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    627\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[1;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1173\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m             \u001b[0mfile_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m             \u001b[0mfile_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_open_fd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loop through all files, calculate MFCCs, save them to the appropriate directory\n",
    "start = time.time()\n",
    "\n",
    "for i in all_words:\n",
    "    #move to the directory for the ith word\n",
    "    working_path = data_path + \"/\" + i\n",
    "    \n",
    "    #loop through each file in the word's directory\n",
    "    for j in os.listdir(working_path):\n",
    "        #define paths we'll need\n",
    "        word_path = i + '/' + j\n",
    "        file_path = data_path + word_path\n",
    "        \n",
    "        #load audio file, GSC is sampled at 16000Hz\n",
    "        y, sr = librosa.load(file_path, sr = 16000)\n",
    "        \n",
    "        # quantize data\n",
    "        y = torch.from_numpy(y)\n",
    "        \n",
    "        quant = quantize_data(y, num_bits=8)\n",
    "        \n",
    "        #define save location directory\n",
    "        #word_dir = i + '_quant'\n",
    "        \n",
    "        #saving file \n",
    "        #torch.save(y, 'Users/Shared/back up fix/quantized/%s.npy' % i)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
