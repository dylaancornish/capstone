{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d7add39",
   "metadata": {},
   "source": [
    "Code assumes that data is in same directory as capstone_repo directory:  \n",
    "```\n",
    "capstone_repo  \n",
    "│   README.md  \n",
    "│   gsc_mfcc_extraction.ipynb    \n",
    "│  \n",
    "speech_commands_v0.02  \n",
    "└───backward  \n",
    "│   │   file01.wav  \n",
    "│   │   file02.wav (etc)  \n",
    "└───bed  \n",
    "│   |..etc  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2331b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import time\n",
    "import pandas as pd\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee295c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/Users/Shared/back up fix/speech_commands_v0.02/'\n",
    "data_path = '../speech_commands_v0.02/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f6d77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../speech_commands_v0.02/',\n",
       " ['backward',\n",
       "  'bed',\n",
       "  'bird',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'down',\n",
       "  'eight',\n",
       "  'five',\n",
       "  'follow',\n",
       "  'forward',\n",
       "  'four',\n",
       "  'go',\n",
       "  'happy',\n",
       "  'house',\n",
       "  'learn',\n",
       "  'left',\n",
       "  'marvin',\n",
       "  'nine',\n",
       "  'no',\n",
       "  'off',\n",
       "  'on',\n",
       "  'one',\n",
       "  'right',\n",
       "  'seven',\n",
       "  'sheila',\n",
       "  'six',\n",
       "  'stop',\n",
       "  'three',\n",
       "  'tree',\n",
       "  'two',\n",
       "  'up',\n",
       "  'visual',\n",
       "  'wow',\n",
       "  'yes',\n",
       "  'zero',\n",
       "  '_background_noise_'],\n",
       " ['.DS_Store',\n",
       "  'LICENSE',\n",
       "  'README.md',\n",
       "  'testing_list.txt',\n",
       "  'validation_list.txt'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of word directories in speech commands dataset\n",
    "list(os.walk(data_path))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5286dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ['backward',\n",
    "  'bed',\n",
    "  'bird',\n",
    "  'cat',\n",
    "  'dog',\n",
    "  'down',\n",
    "  'eight',\n",
    "  'five',\n",
    "  'follow',\n",
    "  'forward',\n",
    "  'four',\n",
    "  'go',\n",
    "  'happy',\n",
    "  'house',\n",
    "  'learn',\n",
    "  'left',\n",
    "  'marvin',\n",
    "  'nine',\n",
    "  'no',\n",
    "  'off',\n",
    "  'on',\n",
    "  'one',\n",
    "  'right',\n",
    "  'seven',\n",
    "  'sheila',\n",
    "  'six',\n",
    "  'stop',\n",
    "  'three',\n",
    "  'tree',\n",
    "  'two',\n",
    "  'up',\n",
    "  'visual',\n",
    "  'wow',\n",
    "  'yes',\n",
    "  'zero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f88ba77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only these 20 words will act as keywords\n",
    "word_list = ['up','down','left', 'right', 'stop', 'go', 'yes', 'no', 'on', 'off', 'one', 'two', \n",
    "             'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero']\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64c3178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backward', 'bed', 'bird', 'cat', 'dog', 'follow', 'forward', 'happy', 'house', 'learn', 'marvin', 'sheila', 'tree', 'visual', 'wow']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the other 15 words will be combined into one class of rejection words\n",
    "rejection_words = [i for i in all_words if i not in word_list]\n",
    "print(rejection_words)\n",
    "len(rejection_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e64b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to see if individual audio files will work correctly\n",
    "y, sr = librosa.load((data_path + '/bird/0a7c2a8d_nohash_0.wav'), sr = 16000)\n",
    "y1, sr1 = librosa.load((data_path + '/down/00f0204f_nohash_0.wav'), sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeeef4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quantize_data(data, num_bits = 8, data_min=-1, data_max=1):\n",
    "#     '''\n",
    "#     Quantizes audio data based on number of bits and desired minimum and maximum\n",
    "    \n",
    "#     Parameters:\n",
    "#     ------------\n",
    "#     data - array containing time series of audio\n",
    "#     num_bits - integer specifying number of bits to use, default 8 for MAX78000\n",
    "#     data_min - desired minimum of quantized data\n",
    "#     data_max - desired maximum of quantized data\n",
    "    \n",
    "#     Returns:\n",
    "#     ------------\n",
    "#     q_data - array with quantized data between data_min and data_max\n",
    "#     '''\n",
    "    \n",
    "#     step_size = 2.0/(2**num_bits)\n",
    "#     max_val = 2**num_bits -1\n",
    "#     q_data = np.round(data / step_size)\n",
    "#     q_data = np.clip(q_data, np.round(-max_val / 2), np.round(max_val/2))\n",
    "#     q_data = q_data / (2**num_bits / 2)\n",
    "#     q_data = np.clip(q_data, data_min, data_max)\n",
    "#     return q_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc39ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_data(data, num_bits=8):\n",
    "    step_size = 2.0/2**num_bits\n",
    "    max_val = 2**num_bits -1\n",
    "    q_data = np.round((data - (-1))/ step_size)\n",
    "    q_data = np.clip(q_data, 0, max_val)\n",
    "    q_data /= 256.\n",
    "    q_data = np.round(((q_data - 0.5) * 256))\n",
    "    q_data = np.clip(q_data, -128, 127) / 128.\n",
    "    return q_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16dd2aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4867\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "#let's test if quantize audio works as intended:\n",
    "print(len(np.unique(y)))\n",
    "yq = quantize_data(y)\n",
    "print(len(np.unique(yq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73b4bd",
   "metadata": {},
   "source": [
    "Converts test file y from 4867 values to 75 unique values. Is this what we should expect? Since our quantize function works with a uniform spacing of step_size, our y test file should have a range of about 75 / 256 before quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6835b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.289 percent of possible values are represented in original audio file\n",
      "So we should expect approximately 73.984 unique values in the transformed file\n"
     ]
    }
   ],
   "source": [
    "percent = np.round(((y.max() - y.min()) / 2),3)\n",
    "print(percent, 'percent of possible values are represented in original audio file')\n",
    "print('So we should expect approximately', percent * 256, 'unique values in the transformed file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5308ffe",
   "metadata": {},
   "source": [
    "Let's try with another file y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7854853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.568 values expected\n",
      "45 unique values after\n"
     ]
    }
   ],
   "source": [
    "expected = np.round(((y1.max() - y1.min()) / 2),3) * 256\n",
    "yq1 = quantize_data(y1)\n",
    "print(expected, 'values expected')\n",
    "print(len(np.unique(yq1)), 'unique values after')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99298a9",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d6d5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backward\n",
      "bed\n",
      "bird\n",
      "cat\n",
      "dog\n",
      "down\n",
      "eight\n",
      "five\n",
      "follow\n",
      "forward\n",
      "four\n",
      "go\n",
      "happy\n",
      "house\n",
      "learn\n",
      "left\n",
      "marvin\n",
      "nine\n",
      "no\n",
      "off\n",
      "on\n",
      "one\n",
      "right\n",
      "seven\n",
      "sheila\n",
      "six\n",
      "stop\n",
      "three\n",
      "tree\n",
      "two\n",
      "up\n",
      "visual\n",
      "wow\n",
      "yes\n",
      "zero\n",
      "824.4822390079498\n"
     ]
    }
   ],
   "source": [
    "#loop through all files, calculate MFCCs, save them to the appropriate directory\n",
    "start = time.time()\n",
    "\n",
    "base_dir = os.path.join('..','speech_commands_quantized')\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "for i in all_words:\n",
    "    #move to the directory for the ith word\n",
    "    working_path = data_path + \"/\" + i\n",
    "    print(i)\n",
    "\n",
    "    save_dir = os.path.join(base_dir, i)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    #loop through each file in the word's directory\n",
    "    for j in os.listdir(working_path):\n",
    "        #define paths we'll need\n",
    "        word_path = i + '/' + j\n",
    "        file_path = data_path + word_path\n",
    "        \n",
    "        #load audio file, GSC is sampled at 16000Hz\n",
    "        y, sr = librosa.load(file_path, sr = 16000)\n",
    "        quant = quantize_data(y, num_bits=8)\n",
    "        \n",
    "        save_path = os.path.join(base_dir, i, os.path.splitext(j)[0])\n",
    "        \n",
    "        np.save(save_path, quant)\n",
    "        \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
