{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d7add39",
   "metadata": {},
   "source": [
    "Code assumes that data is in same directory as capstone_repo directory:  \n",
    "```\n",
    "capstone_repo  \n",
    "│   README.md  \n",
    "│   gsc_mfcc_extraction.ipynb    \n",
    "│  \n",
    "speech_commands_v0.02  \n",
    "└───backward  \n",
    "│   │   file01.wav  \n",
    "│   │   file02.wav (etc)  \n",
    "└───bed  \n",
    "│   |..etc  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b487a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 1600\n",
    "\n",
    "#Functions for a\n",
    "\n",
    "def add_white_noise(audio, noise_var_coeff):\n",
    "        \"\"\"Adds zero mean Gaussian noise to image with specified variance.\n",
    "        \"\"\"\n",
    "        coeff = noise_var_coeff * np.mean(np.abs(audio))\n",
    "        noisy_audio = audio + coeff * np.random.randn(len(audio))\n",
    "        return noisy_audio\n",
    "\n",
    "\n",
    "def shift(audio, shift_sec, fs):\n",
    "        \"\"\"Shifts audio.\n",
    "        \"\"\"\n",
    "        shift_count = int(shift_sec * fs)\n",
    "        return np.roll(audio, shift_count)\n",
    "\n",
    "    \n",
    "def stretch(audio, rate=1):\n",
    "        \"\"\"Stretches audio with specified ratio.\n",
    "        \"\"\"\n",
    "        input_length = 16000\n",
    "        audio2 = librosa.effects.time_stretch(audio, rate)\n",
    "        if len(audio2) > input_length:\n",
    "            audio2 = audio2[:input_length]\n",
    "        else:\n",
    "            audio2 = np.pad(audio2, (0, max(0, input_length - len(audio2))), \"constant\")\n",
    "\n",
    "        return audio2\n",
    "\n",
    "def augment_shift(audio, fs = 16000, verbose=False):\n",
    "        \"\"\"Augments audio by adding random shift\n",
    "        \"\"\"\n",
    "        random_shift_time = np.random.uniform(-0.1,0.1)\n",
    "        shifted_audio = shift(audio, random_shift_time, fs)\n",
    "        return shifted_audio\n",
    "    \n",
    "def augment_stretch(audio, fs = 16000, verbose=False):\n",
    "        \"\"\"Augments audio by adding random stretch\"\"\"\n",
    "        \n",
    "        random_strech_coeff = np.random.uniform(0.8, 1.3)\n",
    "        stretched_audio = tsm.wsola(audio, random_strech_coeff)\n",
    "        return stretched_audio\n",
    "        \n",
    "def augment_noise(audio, fs = 16000, verbose=False):\n",
    "        \"\"\" Augments auido by adding random white noise\"\"\"\n",
    "        \n",
    "        random_noise_var_coeff = np.random.uniform(0,1)\n",
    "        noisy_audio = add_white_noise(audio, random_noise_var_coeff)\n",
    "        return noisy_audio\n",
    "\n",
    "\n",
    "\n",
    "def __parse_augmentation(self, augmentation):\n",
    "        self.augmentation = augmentation\n",
    "        if augmentation:\n",
    "            if 'aug_num' not in augmentation:\n",
    "                print('No key `aug_num` in input augmentation dictionary! ',\n",
    "                      'Using 0.')\n",
    "                self.augmentation['aug_num'] = 0\n",
    "            elif self.augmentation['aug_num'] != 0:\n",
    "                if 'noise_var' not in augmentation:\n",
    "                    print('No key `noise_var` in input augmentation dictionary! ',\n",
    "                          'Using defaults: [Min: 0., Max: 1.]')\n",
    "                    self.augmentation['noise_var'] = {'min': 0., 'max': 1.}\n",
    "                if 'shift' not in augmentation:\n",
    "                    print('No key `shift` in input augmentation dictionary! '\n",
    "                          'Using defaults: [Min:-0.1, Max: 0.1]')\n",
    "                    self.augmentation['shift'] = {'min': -0.1, 'max': 0.1}\n",
    "                if 'strech' not in augmentation:\n",
    "                    print('No key `strech` in input augmentation dictionary! '\n",
    "                          'Using defaults: [Min: 0.8, Max: 1.3]')\n",
    "                    self.augmentation['strech'] = {'min': 0.8, 'max': 1.3}\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "def __init__(self, root, classes, d_type, t_type, transform=None, quantization_scheme=None,\n",
    "                 augmentation=None, download=False, save_unquantized=False):\n",
    "\n",
    "        self.root = root\n",
    "        self.classes = classes\n",
    "        self.d_type = d_type\n",
    "        self.t_type = t_type\n",
    "        self.transform = transform\n",
    "        self.save_unquantized = save_unquantized\n",
    "\n",
    "        self.__parse_quantization(quantization_scheme)\n",
    "        self.__parse_augmentation(augmentation)\n",
    "\n",
    "        if not self.save_unquantized:\n",
    "            self.data_file = 'dataset2.pt'\n",
    "        else:\n",
    "            self.data_file = 'unquantized.pt'\n",
    "\n",
    "        if download:\n",
    "            self.__download()\n",
    "\n",
    "        self.data, self.targets, self.data_type = torch.load(os.path.join(\n",
    "            self.processed_folder, self.data_file))\n",
    "\n",
    "        print(f'\\nProcessing {self.d_type}...')\n",
    "        self.__filter_dtype()\n",
    "        self.__filter_classes()\n",
    "    \n",
    "\n",
    "augmentation = {'aug_num': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2331b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import time\n",
    "import pandas as pd\n",
    "import errno\n",
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import time\n",
    "import urllib\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.model_zoo import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "import librosa\n",
    "import pytsmod as tsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee295c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../speech_commands_v0.02/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8f6d77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../speech_commands_v0.02/',\n",
       " ['backward',\n",
       "  'bed',\n",
       "  'bird',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'down',\n",
       "  'eight',\n",
       "  'five',\n",
       "  'follow',\n",
       "  'forward',\n",
       "  'four',\n",
       "  'go',\n",
       "  'happy',\n",
       "  'house',\n",
       "  'learn',\n",
       "  'left',\n",
       "  'marvin',\n",
       "  'nine',\n",
       "  'no',\n",
       "  'off',\n",
       "  'on',\n",
       "  'one',\n",
       "  'right',\n",
       "  'seven',\n",
       "  'sheila',\n",
       "  'six',\n",
       "  'stop',\n",
       "  'three',\n",
       "  'tree',\n",
       "  'two',\n",
       "  'up',\n",
       "  'visual',\n",
       "  'wow',\n",
       "  'yes',\n",
       "  'zero',\n",
       "  '_background_noise_'],\n",
       " ['.DS_Store',\n",
       "  'LICENSE',\n",
       "  'README.md',\n",
       "  'testing_list.txt',\n",
       "  'validation_list.txt'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of word directories in speech commands dataset\n",
    "list(os.walk(data_path))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5286dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ['backward',\n",
    "  'bed',\n",
    "  'bird',\n",
    "  'cat',\n",
    "  'dog',\n",
    "  'down',\n",
    "  'eight',\n",
    "  'five',\n",
    "  'follow',\n",
    "  'forward',\n",
    "  'four',\n",
    "  'go',\n",
    "  'happy',\n",
    "  'house',\n",
    "  'learn',\n",
    "  'left',\n",
    "  'marvin',\n",
    "  'nine',\n",
    "  'no',\n",
    "  'off',\n",
    "  'on',\n",
    "  'one',\n",
    "  'right',\n",
    "  'seven',\n",
    "  'sheila',\n",
    "  'six',\n",
    "  'stop',\n",
    "  'three',\n",
    "  'tree',\n",
    "  'two',\n",
    "  'up',\n",
    "  'visual',\n",
    "  'wow',\n",
    "  'yes',\n",
    "  'zero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8f88ba77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only these 20 words will act as keywords\n",
    "word_list = ['up','down','left', 'right', 'stop', 'go', 'yes', 'no', 'on', 'off', 'one', 'two', \n",
    "             'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero']\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64c3178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backward', 'bed', 'bird', 'cat', 'dog', 'follow', 'forward', 'happy', 'house', 'learn', 'marvin', 'sheila', 'tree', 'visual', 'wow']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the other 15 words will be combined into one class of rejection words\n",
    "rejection_words = [i for i in all_words if i not in word_list]\n",
    "print(rejection_words)\n",
    "len(rejection_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6519027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create base MFCC directory\n",
    "if not os.path.exists('mfccs'):\n",
    "    os.makedirs('mfccs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f34d8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training, validation, and test directories\n",
    "if not os.path.exists('mfccs/training'):\n",
    "    os.makedirs('mfccs/training')\n",
    "    \n",
    "if not os.path.exists('mfccs/validation'):\n",
    "    os.makedirs('mfccs/validation')\n",
    "    \n",
    "if not os.path.exists('mfccs/test'):\n",
    "    os.makedirs('mfccs/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b9b09d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create subdirectories that will contain MFCCs for each word\n",
    "for directory in list(os.walk('mfccs'))[0][1]:\n",
    "    for i in all_words:\n",
    "        word_dir = 'mfccs/' + directory + '/' + i\n",
    "        if not os.path.exists(word_dir):\n",
    "            os.makedirs(word_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b4aa496b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['right/a69b9b3e_nohash_0.wav', 'right/439c84f4_nohash_1.wav',\n",
       "       'right/409c962a_nohash_1.wav', 'right/dbaf8fc6_nohash_2.wav',\n",
       "       'right/a6d586b7_nohash_1.wav'], dtype='<U30')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation samples: 9981\n"
     ]
    }
   ],
   "source": [
    "#read in list of validation files\n",
    "val_path = data_path + 'validation_list.txt'\n",
    "val_list = np.loadtxt(val_path, dtype = 'str')\n",
    "display(val_list[:5])\n",
    "print('Number of validation samples:', len(val_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "264221d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['right/bb05582b_nohash_3.wav', 'right/97f4c236_nohash_2.wav',\n",
       "       'right/f2e59fea_nohash_3.wav', 'right/fdb5155e_nohash_2.wav',\n",
       "       'right/dc75148d_nohash_0.wav'], dtype='<U30')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing samples: 11005\n"
     ]
    }
   ],
   "source": [
    "#read in list of test files\n",
    "test_path = data_path + 'testing_list.txt'\n",
    "test_list = np.loadtxt(test_path, dtype = 'str')\n",
    "display(test_list[:5])\n",
    "print('Number of testing samples:', len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d6d5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MFCCs in validation folder\n",
      "0 MFCCs in testing folder\n",
      "1 MFCCs in training folder\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36576/1883885141.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworking_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#define paths we'll need\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mword_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "#loop through all files, calculate MFCCs, save them to the appropriate directory\n",
    "start = time.time()\n",
    "\n",
    "#GSC is sampled at 16000Hz\n",
    "sample_rate = 16000\n",
    "\n",
    "fs = 16000\n",
    "\n",
    "for i in all_words:\n",
    "    #move to the directory for the ith word\n",
    "    working_path = data_path + i\n",
    "    \n",
    "    #loop through each file in the word's directory\n",
    "    for j in os.listdir(working_path):\n",
    "        #define paths we'll need\n",
    "        word_path = i + '/' + j\n",
    "        file_path = data_path + word_path\n",
    "        \n",
    "        #load audio file\n",
    "        y, sr = librosa.load(file_path, sr = sample_rate)\n",
    "        \n",
    "        #pad shorter audio clips that don't have 16000 data points\n",
    "        if (len(y) < sample_rate):\n",
    "            y = np.pad(y, (0, (sample_rate - len(y))))\n",
    "            \n",
    "            \n",
    "        #augment training set\n",
    "        if (word_path not in test_list) and (word_path not in val_list):\n",
    "            #Augment Audio 3 different ways\n",
    "            aug_audio1 = augment_shift(y, fs)\n",
    "            aug_audio2 = augment_stretch(y, fs)\n",
    "            aug_audio3 = augment_noise(y, fs)\n",
    "            \n",
    "            #Calculate MFCCs for augmented audio + normal audio\n",
    "            mfcc = librosa.feature.mfcc(y = y, sr = sr)\n",
    "            mfcc_aug1 = librosa.feature.mfcc(y = aug_audio1, sr = sr)\n",
    "            mfcc_aug2 = librosa.feature.mfcc(y = aug_audio2, sr = sr)\n",
    "            mfcc_aug3 = librosa.feature.mfcc(y = aug_audio3, sr = sr)\n",
    "            \n",
    "            #define save location directory\n",
    "            word_dir = i + '_mfcc'\n",
    "            \n",
    "            #Set training save path\n",
    "            save_path = os.path.join('mfccs', 'training', i, os.path.splitext(j)[0])\n",
    "            np.save(save_path, mfcc)\n",
    "            save_path = os.path.join('mfccs', 'training', i, os.path.splitext(j)[0])\n",
    "            np.save(save_path, mfcc_aug1)\n",
    "            save_path = os.path.join('mfccs', 'training', i, os.path.splitext(j)[0])\n",
    "            np.save(save_path, mfcc_aug2)\n",
    "            save_path = os.path.join('mfccs', 'training', i, os.path.splitext(j)[0])\n",
    "            np.save(save_path, mfcc_aug3)\n",
    "\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            #calculate MFCC\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        \n",
    "            #define save location directory\n",
    "            word_dir = i + '_mfcc'\n",
    "        \n",
    "            #set save path to either train, test, or validation\n",
    "            if word_path in test_list:\n",
    "                save_path = os.path.join('mfccs', 'test', i, os.path.splitext(j)[0])\n",
    "            elif word_path in val_list:\n",
    "                save_path = os.path.join('mfccs', 'validation', i, os.path.splitext(j)[0])\n",
    "            \n",
    "            #save MFCC\n",
    "            np.save(save_path, mfcc)\n",
    "            \n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "39bd0bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ntpath' from 'C:\\\\Users\\\\hdfer\\\\anaconda3\\\\lib\\\\ntpath.py'>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "80fc9963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9981 MFCCs in validation folder\n",
      "11005 MFCCs in testing folder\n",
      "84843 MFCCs in training folder\n"
     ]
    }
   ],
   "source": [
    "#let's make sure there are the right number of MFCCs in validation, test, and train\n",
    "val_count = 0\n",
    "test_count = 0\n",
    "train_count = 0\n",
    "for i in range(1,36):\n",
    "    val_count += len(list(os.walk('mfccs/validation'))[i][2])\n",
    "    test_count += len(list(os.walk('mfccs/test'))[i][2]) \n",
    "    train_count += len(list(os.walk('mfccs/training'))[i][2])\n",
    "print(val_count, 'MFCCs in validation folder')\n",
    "print(test_count, 'MFCCs in testing folder')\n",
    "print(train_count, 'MFCCs in training folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291681f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
